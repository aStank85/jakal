# v0.5 - Web Scraping Setup

Version 0.5 adds Playwright-based web scraping to automatically fetch player stats from R6 Tracker, eliminating the need for manual copy-pasting.

## Installation

### 1. Install Playwright

```bash
pip install playwright
```

### 2. Install Browser Binaries

Playwright needs browser binaries to run. Install them with:

```bash
python -m playwright install
```

Or install just Chromium (faster):

```bash
python -m playwright install chromium
```

## Usage

### Basic Scraping

Scrape stats for a player:

```bash
python scripts/scrape_drawer.py --username SaucedZyn
```

### With Season and Platform

```bash
python scripts/scrape_drawer.py --username SaucedZyn --season Y10S4 --platform ubi
```

### Headless Mode

Run in background (faster, no visible browser):

```bash
python scripts/scrape_drawer.py --username SaucedZyn --headless
```

### Debug Mode

Pause at the drawer for interactive inspection:

```bash
python scripts/scrape_drawer.py --username SaucedZyn --pause
```

### Dump Raw Data

Write debug files to troubleshoot extraction issues:

```bash
python scripts/scrape_drawer.py --username SaucedZyn --dump-raw
```

This creates:
- `debug_raw.txt` - Full page text
- `debug_drawer.txt` - Extracted drawer portion

### Take Screenshot

Save a screenshot of the page:

```bash
python scripts/scrape_drawer.py --username SaucedZyn --screenshot screenshot.png
```

## Command-Line Arguments

| Argument | Default | Description |
|----------|---------|-------------|
| `--username` | Required | R6 username |
| `--season` | Y10S4 | Season identifier |
| `--platform` | ubi | Platform (ubi, psn, xbl) |
| `--headed` | False | Run with visible browser window |
| `--headless` | False | Run in background (default) |
| `--pause` | False | Pause for debugging |
| `--storage-state` | storage_state.json | Path to cookies file |
| `--min-rounds` | 10 | Minimum rounds threshold |
| `--device-tag` | pc | Device tag (pc, xbox, playstation) |
| `--dump-raw` | False | Write debug files |
| `--screenshot` | None | Screenshot path |

## Storage State (Cookie Persistence)

The scraper automatically saves cookies to `storage_state.json` after the first successful run.

### How It Works

1. **First run:** Browser opens, you pass consent manually, cookies are saved
2. **Subsequent runs:** Cookies are loaded automatically, consent is bypassed
3. **Reset:** Delete `storage_state.json` to clear cookies

### Example Workflow

```bash
# First time - pass consent in browser
python scripts/scrape_drawer.py --username SaucedZyn --headed

# Future runs - cookies loaded, faster
python scripts/scrape_drawer.py --username SaucedZyn --headless
```

## Troubleshooting

### "Playwright not installed" Error

**Problem:** Playwright package not installed

**Solution:**
```bash
pip install playwright
python -m playwright install
```

### Consent Wall Blocks Request

**Problem:** R6 Tracker shows consent overlay, scraper can't proceed

**Solution:** Run in headed mode and pass consent manually:
```bash
python scripts/scrape_drawer.py --username SaucedZyn --headed
```

After passing consent once, cookies are saved and future runs work in headless mode.

### "Snapshot validation failed" Error

**Problem:** Scraped data has zeros or missing fields (likely blocked page)

**Possible causes:**
- Consent wall blocked the request
- Player profile doesn't exist
- R6 Tracker is down or slow

**Solution:**
1. Try headed mode: `--headed`
2. Check player exists on R6 Tracker website
3. Use `--dump-raw` to inspect extracted text
4. Use `--pause` to debug selectors

### Timeout Errors

**Problem:** "Timeout waiting for 'Game' section"

**Possible causes:**
- R6 Tracker changed their layout
- Page loaded incorrectly
- Network issues

**Solution:**
1. Use `--pause` to inspect page state
2. Use `--screenshot screenshot.png` to see what was loaded
3. Check if R6 Tracker is accessible in your browser

### Parse Errors

**Problem:** "Failed to parse stats"

**Possible causes:**
- Drawer extraction got wrong element
- R6 Tracker layout changed

**Solution:**
1. Use `--dump-raw` to see extracted text
2. Compare `debug_drawer.txt` to expected format
3. Use `--pause` to manually inspect drawer

## How It Works

### Scraping Flow

1. **Launch browser** (headed or headless)
2. **Navigate** to `https://r6.tracker.network/r6siege/profile/{platform}/{username}/overview`
3. **Click** "View All Stats" button
4. **Wait** for drawer to load
5. **Extract** drawer text
6. **Parse** using existing R6TrackerParser
7. **Validate** to prevent junk inserts
8. **Insert** into database
9. **Calculate** metrics
10. **Display** results

### Validation Rules

To prevent inserting junk data from blocked pages, the scraper validates:

1. **Hard-fail:** `rounds_played == 0` → Reject
2. **Hard-fail:** Both `matches == 0` AND `time_played_hours == 0` → Reject
3. **Soft validation:** If `rounds_played < 10` AND at least one key field is 0 → Reject

This ensures only real player data gets into the database.

### Robust Extraction

The scraper uses a fallback strategy for drawer extraction:

1. **Primary:** Find "Game" header, walk up DOM to parent container
2. **Fallback:** Get full page text, slice from "Game" section to footer

This makes the scraper resilient to R6 Tracker layout changes.

## Testing

### Run Unit Tests

```bash
pytest tests/test_scraper.py
```

These tests don't hit the live web and run quickly.

### Run Web Integration Test

```bash
RUN_WEB_TESTS=1 pytest tests/test_scraper.py
```

This actually scrapes R6 Tracker (slower, requires internet).

## Examples

### Batch Scraping Multiple Players

```bash
# Scrape entire team
for player in PlayerA PlayerB PlayerC PlayerD PlayerE; do
    python scripts/scrape_drawer.py --username $player --headless
done
```

### Scheduled Updates

Add to cron for automatic daily updates:

```bash
# Daily at 2 AM
0 2 * * * cd /path/to/jakal-mvp && python scripts/scrape_drawer.py --username SaucedZyn --headless
```

## Known Limitations (v0.5)

1. **Consent walls:** Require manual intervention on first run
2. **Rate limiting:** R6 Tracker may block rapid requests (add delays for batch scraping)
3. **Layout changes:** If R6 Tracker redesigns, selectors may need updating
4. **Season dropdown:** Currently doesn't select specific season (uses current season shown)

## What's Next (v0.6+)

Future improvements planned:
- Automatic consent bypass (browser profiles)
- Season dropdown selection
- Rate limiting / delays for batch scraping
- Better error recovery
- Multi-platform scraping (PC, Xbox, PlayStation)
